{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, confusion_matrix, make_scorer, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddrtree_data = pd.read_csv(\"../tree_proj_complete_BIDMC.csv\")\n",
    "ukb_data = pd.read_csv(\"../external_val/ukb_broadqrs_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting UKB's dimension coordinates (Z1 and Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z1\n",
    "X = ddrtree_data[['X20', 'X42', 'X41', 'X8', 'X7', 'X22', 'X50',\n",
    "       'X40', 'X31', 'X29', 'X21', 'X2', 'X4', 'X17', 'X38', 'X37', 'X35',\n",
    "       'X16', 'X43', 'X6', 'X30', 'X33', 'X15', 'X9', 'X18', 'X19', 'X23',\n",
    "       'X25', 'X1', 'X12', 'X46', 'X34', 'X45', 'X3', 'X49', 'X39', 'X24',\n",
    "       'X14', 'X36', 'X10', 'X44', 'X26', 'X28', 'X13', 'X48', 'X11', 'X27',\n",
    "       'X47', 'X5', 'X51', 'X32']]\n",
    "y_Z1 = ddrtree_data[['Z1']]\n",
    "y_Z2 = ddrtree_data[['Z2']]\n",
    "\n",
    "X_test = ukb_data[['X20', 'X42', 'X41', 'X8', 'X7', 'X22', 'X50',\n",
    "       'X40', 'X31', 'X29', 'X21', 'X2', 'X4', 'X17', 'X38', 'X37', 'X35',\n",
    "       'X16', 'X43', 'X6', 'X30', 'X33', 'X15', 'X9', 'X18', 'X19', 'X23',\n",
    "       'X25', 'X1', 'X12', 'X46', 'X34', 'X45', 'X3', 'X49', 'X39', 'X24',\n",
    "       'X14', 'X36', 'X10', 'X44', 'X26', 'X28', 'X13', 'X48', 'X11', 'X27',\n",
    "       'X47', 'X5', 'X51', 'X32']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_z1, X_val_z1, y_train_z1, y_val_z1 = train_test_split(X, y_Z1, test_size=0.25, random_state=42)\n",
    "print(X_train_z1.shape)\n",
    "print(X_val_z1.shape)\n",
    "\n",
    "# Create and train the XGBoost model -\n",
    "start_time = time.time()\n",
    "model_z1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model_z1.fit(X_train_z1, y_train_z1,verbose = True)\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"The task took {elapsed_minutes:.2f} minutes to run.\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_z1 = model_z1.predict(X_val_z1)\n",
    "\n",
    "# Calculate the Root Mean Squared Error (RMSE) to evaluate the model's performance\n",
    "rmse = mean_squared_error(y_val_z1, y_pred_z1, squared=False)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "r2 = r2_score(y_val_z1, y_pred_z1)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "mae = mean_absolute_error(y_val_z1, y_pred_z1)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new labels!\n",
    "start_time = time.time()\n",
    "y_pred_new_z1 = model_z1.predict(X_test)\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"The task took {elapsed_minutes:.2f} minutes to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_z2, X_val_z2, y_train_z2, y_val_z2 = train_test_split(X, y_Z2, test_size=0.25, random_state=42)\n",
    "print(X_train_z2.shape)\n",
    "print(X_val_z2.shape)\n",
    "\n",
    "# Create and train the XGBoost model - \n",
    "start_time = time.time()\n",
    "model_z2 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model_z2.fit(X_train_z2, y_train_z2,verbose = True)\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"The task took {elapsed_minutes:.2f} minutes to run.\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_z2 = model_z2.predict(X_val_z2)\n",
    "\n",
    "# Calculate the Root Mean Squared Error (RMSE) to evaluate the model's performance\n",
    "rmse = mean_squared_error(y_val_z2, y_pred_z2, squared=False)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "r2 = r2_score(y_val_z2, y_pred_z2)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "mae = mean_absolute_error(y_val_z2, y_pred_z2)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# make new labels!\n",
    "start_time = time.time()\n",
    "y_pred_new_z2 = model_z2.predict(X_test)\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"The task took {elapsed_minutes:.2f} minutes to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new labels!\n",
    "start_time = time.time()\n",
    "y_pred_new_z2 = model_z2.predict(X_test)\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"The task took {elapsed_minutes:.2f} minutes to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Estimating algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_matrix = ddrtree_data[['Z1', 'Z2']].to_numpy()\n",
    "y_pred_new_z1 = y_pred_new_z1.reshape(-1, 1)\n",
    "y_pred_new_z2 = y_pred_new_z2.reshape(-1, 1)\n",
    "pred_matrix = np.concatenate((y_pred_new_z1, y_pred_new_z2), axis = 1)\n",
    "print(orig_matrix.shape)\n",
    "print(pred_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../external_val/orig_matrix.npy', orig_matrix)\n",
    "np.save('../external_val/pred_matrix.npy', pred_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance estimating algorithm was run using the distance_est.py script on HPC resources. \n",
    "\n",
    "The resulting output is loaded back here for to predict the phenogroup assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting phenogroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_matrix = np.load(\"../external_val/new_pred_matrix_xgboost_ukb.npy\")\n",
    "new_pred_df = pd.DataFrame(data=new_pred_matrix, columns=['Z1', 'Z2'])\n",
    "result = pd.concat([ukb_data, new_pred_df], axis=1)\n",
    "\n",
    "print(ddrtree_data.shape)\n",
    "print(ukb_data.shape)\n",
    "\n",
    "X = ddrtree_data[['Z1', 'Z2']]\n",
    "y = ddrtree_data['merged_branchcoords'].values.flatten()\n",
    "X_test = result[['Z1', 'Z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10) \n",
    "\n",
    "k_range = range(1, 200)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_validate for KNeighborsClassifier with k neighbors\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, average='weighted'),\n",
    "        'recall': make_scorer(recall_score, average='weighted'),\n",
    "        'f1_score': make_scorer(f1_score, average='weighted')\n",
    "    }\n",
    "    scores = cross_validate(knn, X, y, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    # 4. append the scores to the lists\n",
    "    precision_scores.append(np.mean(scores['test_precision']))\n",
    "    recall_scores.append(np.mean(scores['test_recall']))\n",
    "    f1_scores.append(np.mean(scores['test_f1_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_index = np.argmax(f1_scores) # trends follow closely for precision and recall\n",
    "best_k = k_range[best_k_index]\n",
    "best_f1_score = f1_scores[best_k_index]\n",
    "\n",
    "# 5. Plot the metrics across different K values\n",
    "plt.plot(k_range, precision_scores, label='Precision')\n",
    "plt.plot(k_range, recall_scores, label='Recall')\n",
    "plt.plot(k_range, f1_scores, label='F1-Score')\n",
    "plt.scatter(best_k, best_f1_score, color='red', marker='x', label=f'Best K = {best_k}')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Score')\n",
    "plt.title('KNN Performance Metrics')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the figure size for publication\n",
    "plt.gcf().set_size_inches(6, 4)  # Set figure size to 8x6 inches (adjust as needed)\n",
    "\n",
    "# Save the figure with high resolution\n",
    "plt.savefig('../external_val/knn_performance_branch.png', dpi=300, bbox_inches='tight')  # Save as PNG file with DPI 600 and tight bounding box\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X,y)\n",
    "\n",
    "y_test = knn.predict(X_test)\n",
    "\n",
    "columns_from_df = X_test.values\n",
    "y_test_reshaped = y_test[:, np.newaxis]  \n",
    "\n",
    "pred_coords_branches = np.concatenate((columns_from_df, y_test_reshaped), axis=1)\n",
    "pred_coords_branches.shape\n",
    "np.save('../external_val/pred_coords_branches_xgboost_knn_ukb.npy', pred_coords_branches)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
